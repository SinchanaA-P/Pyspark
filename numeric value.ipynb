{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4c98b14-1f0e-4d0b-864d-89eb695a85b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n|amount|qty|\n+------+---+\n|  10.5|  3|\n|  -8.2|  2|\n|  15.0|  4|\n+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [(10.5, 3), (-8.2, 2), (15.0, 4)]\n",
    "df = spark.createDataFrame(data, [\"amount\", \"qty\"])\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3831457-ecf4-4d03-90a7-d3a4d0aefff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|abs(amount)|\n+-----------+\n|       10.5|\n|        8.2|\n|       15.0|\n+-----------+\n\n+----------------+\n|round(amount, 1)|\n+----------------+\n|            10.5|\n|            -8.2|\n|            15.0|\n+----------------+\n\n+------------+\n|CEIL(amount)|\n+------------+\n|          11|\n|          -8|\n|          15|\n+------------+\n\n+-------------+\n|FLOOR(amount)|\n+-------------+\n|           10|\n|           -9|\n|           15|\n+-------------+\n\n+-------------+\n|POWER(qty, 2)|\n+-------------+\n|          9.0|\n|          4.0|\n|         16.0|\n+-------------+\n\n+------------------+\n|         SQRT(qty)|\n+------------------+\n|1.7320508075688772|\n|1.4142135623730951|\n|               2.0|\n+------------------+\n\n+--------------+\n|SIGNUM(amount)|\n+--------------+\n|           1.0|\n|          -1.0|\n|           1.0|\n+--------------+\n\n+------------------+\n|           ln(qty)|\n+------------------+\n|1.0986122886681096|\n|0.6931471805599453|\n|1.3862943611198906|\n+------------------+\n\n+------------------+\n|          EXP(qty)|\n+------------------+\n|20.085536923187668|\n|  7.38905609893065|\n|54.598150033144236|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#wiil return positive value\n",
    "df.select(abs(\"amount\")).show()\n",
    "#wiil round the n decimal value\n",
    "df.select(round(\"amount\", 1)).show()\n",
    "#wll round the number to next\n",
    "df.select(ceil(\"amount\")).show()\n",
    "#will round up number to previous number\n",
    "df.select(floor(\"amount\")).show()\n",
    "#will find the power of the number\n",
    "df.select(pow(\"qty\", 2)).show()\n",
    "#will find the square root of the number\n",
    "df.select(sqrt(\"qty\")).show()\n",
    "#will find the sign of the number\n",
    "df.select(signum(\"amount\")).show()\n",
    "#will find the log og the number\n",
    "df.select(log(\"qty\")).show()\n",
    "#will find the exponential of the number finds e^x\n",
    "df.select(exp(\"qty\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e177c0ce-2727-4233-8d22-7d3149d1808b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|sum(amount)|\n+-----------+\n|       17.3|\n+-----------+\n\n+-----------------+\n|      avg(amount)|\n+-----------------+\n|5.766666666666667|\n+-----------------+\n\n+-----------+\n|min(amount)|\n+-----------+\n|       -8.2|\n+-----------+\n\n+----------+\n|count(qty)|\n+----------+\n|         3|\n+----------+\n\n+-----------+-----------+\n|min(amount)|max(amount)|\n+-----------+-----------+\n|       -8.2|       15.0|\n+-----------+-----------+\n\n+-------+--------+------+------------------+\n|rounded|absolute|square|              sqrt|\n+-------+--------+------+------------------+\n|   10.5|    10.5|   9.0|1.7320508075688772|\n|   -8.2|     8.2|   4.0|1.4142135623730951|\n|   15.0|    15.0|  16.0|               2.0|\n+-------+--------+------+------------------+\n\n+----------+\n|double_qty|\n+----------+\n|         6|\n|         4|\n|         8|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(sum(\"amount\")).show()\n",
    "df.select(avg(\"amount\")).show()\n",
    "df.select(min(\"amount\")).show()\n",
    "df.select(count(\"qty\")).show()\n",
    "df.select(min(\"amount\"), max(\"amount\")).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.select(\n",
    "    round(\"amount\", 2).alias(\"rounded\"),\n",
    "    abs(\"amount\").alias(\"absolute\"),\n",
    "    pow(\"qty\", 2).alias(\"square\"),\n",
    "    sqrt(\"qty\").alias(\"sqrt\")\n",
    ").show()\n",
    "\n",
    "\n",
    "#map- transformation function apply to all column\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select((col(\"qty\") * 2).alias(\"double_qty\")).show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "numeric value",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}